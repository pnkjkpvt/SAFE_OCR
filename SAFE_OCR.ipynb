{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SAFE_OCR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pnkjkpvt/SAFE_OCR/blob/master/SAFE_OCR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jldDRrq86E8p",
        "colab_type": "text"
      },
      "source": [
        "Install necessary modeules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaJRWN8Q6KDq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "a86368d2-0389-4559-a791-c1ec6b801542"
      },
      "source": [
        "!pip install opencv-python \n",
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "!pip install pyyaml h5py  # Required to save models in HDF5 format"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.18.5)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.00~git2288-10f4998a-2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 59 not upgraded.\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.6/dist-packages (0.3.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from pytesseract) (7.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAKoSjMj5qaj",
        "colab_type": "text"
      },
      "source": [
        "Connect to drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNhvwBI_5p3w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8f9b609b-d582-4aad-fbe3-0b631f04973b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!ls /content/gdrive"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "'My Drive'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbNpuBQL7eyC",
        "colab_type": "text"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-Z_uxPy48pc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "import csv\n",
        "import re\n",
        "\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "import pytesseract\n"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MifRdg5y7g1M",
        "colab_type": "text"
      },
      "source": [
        "Setting Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVQxM9Dk5NIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_PATH = F\"/content/gdrive/My Drive/SAFE_OCR/data/\"\n",
        "FILE_PATH = DATA_PATH+\"images/\"\n",
        "TEMPLATE_FILE = DATA_PATH+\"dashed 1.jpg\"  ## File path to the exam-paper template file\n",
        "MAPPING_FILE = DATA_PATH+\"roll-numbers.csv\"\n",
        "\n",
        "MODEL_PATH = F\"/content/gdrive/My Drive/SAFE_OCR/models/\"\n",
        "\n",
        "LEGAL_FILE_EXTENSION = ['jpg','jpeg','png','JPG','JPEG','PNG']\n",
        "\n",
        "PAGE_SCALE = 0.5"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_WK6bj_5Piw",
        "colab_type": "text"
      },
      "source": [
        "Getting Image Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1c4xFpS5O3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Here we're hardcoding the approximate location of Name and Roll_no fields.\n",
        "## TODO identify these regions automatically\n",
        "name_box = [386, 36, 1230, 172]    #Box parameters for Name field\n",
        "roll_box = [1400, 32, 2010, 166]    #Box parameters for Roll_no filed\n",
        "\n",
        "\n",
        "files = [FILE_PATH + f for f in listdir(FILE_PATH) if isfile(join(FILE_PATH, f))]\n"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpJ1RQO6AJt-",
        "colab_type": "text"
      },
      "source": [
        "Defining Useful functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0SHjWAIAOwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_grayscale(image):\n",
        "    # image = cv2.convertScaleAbs(image, alpha=1, beta=0)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    return image"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmRtBKGhF5Lw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_binary_image(image, inverted=False):\n",
        "    # Source : https://docs.opencv.org/master/d7/d4d/tutorial_py_thresholding.html\n",
        "    gray = to_grayscale(image)\n",
        "\n",
        "    if (inverted):\n",
        "        image = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)[1]  \n",
        "    else:\n",
        "        image = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)[1]\n",
        "        # image = cv2.adaptiveThreshold(image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,27,2)\n",
        "\n",
        "    return image"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZOlEWoRF6q_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Post-processing step on OCR output\n",
        "def clean_roll_number(rollno):\n",
        "    # Here there is a need to refine wrong predictions of characters\n",
        "    # Remove spaces from Roll number\n",
        "    rollno = re.sub('\\\\s+', '', rollno)\n",
        "    # 'o' is probably 0\n",
        "    rollno = re.sub('[o,O]', '0', rollno)\n",
        "    # I, i, J, j, l are probably 1\n",
        "    rollno = re.sub('[I,J,l]', '1', rollno)\n",
        "    # S, s is probably 5 or 8\n",
        "    rollno = re.sub('[s,S]', '5', rollno)\n",
        "    # q is probably 9\n",
        "    rollno = re.sub('[q]', '9', rollno)\n",
        "    # b is probably 6\n",
        "    rollno = re.sub('[b]', '6', rollno)\n",
        "    # Neglect all special character\n",
        "    rollno = rollno.upper()\n",
        "    rollno = re.sub('[^A-Z,0-9]', '', rollno)\n",
        "    return rollno"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dm9JwSKdF9Od",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Longest common subsequence\n",
        "def lcs(X, Y):\n",
        "    # find the length of the strings\n",
        "    m = len(X)\n",
        "    n = len(Y)\n",
        "\n",
        "    # declaring the array for storing the dp values\n",
        "    L = [[None] * (n + 1) for i in range(m + 1)]\n",
        "\n",
        "    \"\"\"Following steps build L[m + 1][n + 1] in bottom up fashion \n",
        "    Note: L[i][j] contains length of LCS of X[0..i-1] \n",
        "    and Y[0..j-1]\"\"\"\n",
        "    for i in range(m + 1):\n",
        "        for j in range(n + 1):\n",
        "            if i == 0 or j == 0:\n",
        "                L[i][j] = 0\n",
        "            elif X[i - 1] == Y[j - 1]:\n",
        "                L[i][j] = L[i - 1][j - 1] + 1\n",
        "            else:\n",
        "                L[i][j] = max(L[i - 1][j], L[i][j - 1])\n",
        "\n",
        "                # L[m][n] contains the length of LCS of X[0..n-1] & Y[0..m-1]\n",
        "    return L[m][n]"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_gYwVqmMiOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Edit Distance\n",
        "# An adaptation of @ https://www.geeksforgeeks.org/edit-distance-dp-5/\n",
        "def editDist(str1, str2):\n",
        "    len1 = len(str1)\n",
        "    len2 = len(str2)\n",
        "    # Create a table to store results of subproblems\n",
        "    dp = [[0 for x in range(len2 + 1)] for x in range(len1 + 1)]\n",
        "    # Fill d[][] in bottom up manner\n",
        "    for i in range(len1 + 1):\n",
        "        for j in range(len2 + 1):\n",
        "\n",
        "            # If first string is empty, only option is to insert all characters of second string\n",
        "            if i == 0:\n",
        "                dp[i][j] = j  # Min. operations = j\n",
        "\n",
        "            # If second string is empty, only option is to remove all characters of second string\n",
        "            elif j == 0:\n",
        "                dp[i][j] = i  # Min. operations = i\n",
        "\n",
        "            # If last characters are same, ignore last char and recur for remaining string\n",
        "            elif str1[i - 1] == str2[j - 1]:\n",
        "                dp[i][j] = dp[i - 1][j - 1]\n",
        "\n",
        "            # If last character are different, consider all possibilities and find minimum\n",
        "            else:\n",
        "                dp[i][j] = 1 + min(dp[i][j - 1],  # Insert\n",
        "                                   dp[i - 1][j],  # Remove\n",
        "                                   dp[i - 1][j - 1])  # Replace\n",
        "\n",
        "    return dp[len1][len2]\n"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o32ksoyRGAch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Function to find best matching record from database against given input\n",
        "\"\"\"Param : algorithm = 'ed' or 'lcs'\n",
        "              \n",
        "\"\"\"\n",
        "\n",
        "def find_record(name, roll, algorithm='ed'): \n",
        "    found_record = []\n",
        "    max_sim_score = 0    \n",
        "    least_dist = 100\n",
        "    with open(MAPPING_FILE, 'r') as mapping_file:\n",
        "        record_list = list(csv.reader(mapping_file, delimiter=','))\n",
        "\n",
        "        # Iterate over the list\n",
        "        for record in record_list[1:]:  # TODO- First the program should check if there is no record in row 1, and only then snip it.\n",
        "            name_record = record[1]     # TODO - get rid of numerical indices. Actual indices of 'Name' or 'roll_no' column may be different\n",
        "            roll_record = record[2]\n",
        "            if (name != '' or roll != '') and (name_record != '' and roll_record != ''):\n",
        "\n",
        "                if (algorithm == 'lcs'):    # if LCS algorithm is chosen\n",
        "                    sim_score = lcs(name + roll, name_record + roll_record)\n",
        "                    # sim_score = sim_score/len(name_record)\n",
        "                    if sim_score > max_sim_score:  # then the current record is more similar\n",
        "                        max_sim_score = sim_score\n",
        "                        found_record = [record[1:3]]  # TODO - get rid of constant indices.\n",
        "                    elif sim_score == max_sim_score:\n",
        "                        found_record.append(record[1:3])  # TODO - get rid of constant indices.\n",
        "\n",
        "                elif (algorithm =='ed'):      # if Edit Distance algorithm is chosen\n",
        "                    dist = editDist(name + roll, name_record + roll_record)\n",
        "                    if least_dist > dist: # then the current record is more similar\n",
        "                        least_dist = dist\n",
        "                        found_record = [record[1:3]]  # TODO - get rid of constant indices.\n",
        "                    elif least_dist == dist:\n",
        "                        found_record.append(record[1:3])  # TODO - get rid of constant indices.\n",
        "\n",
        "    # print(found_record)\n",
        "    return found_record"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKB_lfpEU-5S",
        "colab_type": "text"
      },
      "source": [
        "Character Segmentation by identifying rectangular boxes in the image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQPpQydIOi6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Finding Contours of the image\n",
        "def get_contours(img):\n",
        "    # converting to gray scale binary. \n",
        "    threshold = to_binary_image(img)\n",
        "\n",
        "    # Detecting contours \n",
        "    contours,_=cv2.findContours(threshold, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    return contours"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fu2mgnl3yan3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Python code to detect a rectangle from an image. \n",
        "\"\"\"Adapted from \n",
        "https://www.geeksforgeeks.org/python-detect-polygons-in-an-image-using-opencv/\n",
        "https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_contours/py_contour_features/py_contour_features.html\n",
        "\"\"\"\n",
        "\n",
        "def segment_characters (img2):\n",
        "    contours = get_contours(img2)\n",
        "    \n",
        "    # Data structure to save rectangle boundaries\n",
        "    boundaries = {}\n",
        "\n",
        "    # To stop same rectangle to be recorded twice\n",
        "    control_median = -1000\n",
        "\n",
        "    # To select the smallest bounding box for a given character\n",
        "    contorl_area = 100000\n",
        "\n",
        "    # Searching through every region selected.\n",
        "    for cnt in contours : \n",
        "        area = cv2.contourArea(cnt) \n",
        "      \n",
        "        # Shortlisting the regions based on there area. \n",
        "        # TODO : Proper finetuning is required as per the page sizes\n",
        "        if area > 800 and area < 10000:       \n",
        "\n",
        "            bounds = cv2.boundingRect(cnt)\n",
        "            [x,y,w,h] = bounds\n",
        "            x_median = x + w/2      ## TODO : Medians of two adjecent boxes can't be very close. Handle this corner case\n",
        "\n",
        "            ## Save coordinates in proper data structure so that they can be sorted and be used for cropping digits\n",
        "            if (abs(control_median - x_median) > w/2):  # If two boxes are appropriatelt apart.            \n",
        "                control_median = x_median\n",
        "                control_area = area\n",
        "                boundaries[x_median] = bounds\n",
        "            \n",
        "            elif (abs(control_median - x_median) < w/4 and area < control_area):    # If two boxes are too close, then choose the smallest one\n",
        "                boundaries[control_median] = bounds\n",
        "\n",
        "            # Color boxes with background color to remove them from image\n",
        "            color = (255,255,255)\n",
        "            img2 = cv2.rectangle(img2,(x,y), (x+w,y+h), color, 4)\n",
        "            # cv2_imshow(img2)\n",
        "\n",
        "    char_boundary = []\n",
        "    for i in sorted(boundaries.keys()):\n",
        "        char_boundary.append(boundaries[i])\n",
        "  \n",
        "    # print (char_boundary)\n",
        "    cv2_imshow(img2)  \n",
        "    return img2, char_boundary\n"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gIPojyqTa9t",
        "colab_type": "text"
      },
      "source": [
        "Localising digits in the box"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbp_LcJuTaNL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def localise_character(box):\n",
        "    #Find location of digit in the box\n",
        "        box_arr = np.array(box)\n",
        "        \n",
        "        top = 0\n",
        "        for row in box_arr:\n",
        "            if (np.sum(row) >= 255): break            \n",
        "            top = top+1\n",
        "        # print(\"Top :\", top)\n",
        "        \n",
        "        bottom = box_arr.shape[0]\n",
        "        for row in box_arr[::-1]:\n",
        "            if (np.sum(row) >= 255): break            \n",
        "            bottom = bottom-1\n",
        "        # print (\"Bottom :\", bottom)\n",
        "        \n",
        "        left = 0\n",
        "        for row in np.transpose(box_arr):\n",
        "            if (np.sum(row) >= 255): break            \n",
        "            left = left+1\n",
        "        # print (\"Left :\", left)\n",
        "\n",
        "        right = box_arr.shape[1]\n",
        "        for row in np.transpose(box_arr)[::-1]:\n",
        "            if (np.sum(row) >= 255): break            \n",
        "            right = right-1\n",
        "        # print (\"Right :\", right)\n",
        "\n",
        "        LR_mean = int((left+right)/2)\n",
        "        TB_mean = int((top+bottom)/2)\n",
        "        offset = int((max(bottom-top, right-left))/2)\n",
        "\n",
        "        # Ensure an square image\n",
        "        top = max(TB_mean-offset,0)\n",
        "        bottom = top + 2*offset\n",
        "        left = max(LR_mean-offset,0)\n",
        "        right = left + 2*offset\n",
        "\n",
        "        return top, bottom, left, right"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hw_0jZhjUqGe",
        "colab_type": "text"
      },
      "source": [
        "# Processing images Using trained models\n",
        "\n",
        "Using model trained on MNIST data-set to identify digits in roll number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7_S3SxiU5vx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import model_from_json\n",
        "from keras.models import model_from_config\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "##Loading saved models\n",
        "def __load_model(model_dir):\n",
        "    model_file = open(model_dir + 'model.json', 'r')\n",
        "    loaded_model_json = model_file.read()\n",
        "    model_file.close()\n",
        "    loaded_model = model_from_json(loaded_model_json)\n",
        "    # load weights into new model\n",
        "    loaded_model.load_weights(model_dir + \"model.h5\")\n",
        "    print(\"Loaded model from disk\")\n",
        "\n",
        "    # Create a basic model instance\n",
        "    # Model configuration is saved in config.json file\n",
        "\n",
        "    loaded_model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                  optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "    \n",
        "    return loaded_model\n",
        "\n",
        "def load_MNIST_model ():    \n",
        "    return __load_model(MODEL_PATH+'MNIST_Model/')\n",
        "\n",
        "def load_EMNIST_model():\n",
        "    return __load_model(MODEL_PATH+'EMNIST_Model/')"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GW0A1zjY1IEk",
        "colab_type": "text"
      },
      "source": [
        "Prepare data and feed it to model for prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--rW0eg-0_Wi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_data_for_model(org_image, contours):\n",
        "    # print(len(contours))\n",
        "\n",
        "    ## For MNIST model we need to invert the image color\n",
        "    image = to_binary_image(org_image, True)\n",
        "    \n",
        "    # image = cv2.erode(image,(5,5))\n",
        "\n",
        "    ## Smoothen the edges\n",
        "    image = cv2.GaussianBlur(image,(3,3),0)\n",
        "    \n",
        "    data_arr = []\n",
        "\n",
        "    for contour in contours:\n",
        "        [x,y,w,h] = contour\n",
        "\n",
        "        #Remove boundaries\n",
        "        box = image[y+3:y+h-3, x+3:x+w-3] \n",
        "\n",
        "        # No need to process nearly empty boxes\n",
        "        if np.sum(box[5:-5, 5:-5]) < 2550 :\n",
        "            continue \n",
        "            \n",
        "        # box = np.pad(array=box, pad_width= int(w/2), mode='constant', constant_values=0)\n",
        "        top, bottom, left, right = localise_character(box)\n",
        "        \n",
        "        digit = box[top:bottom, left:right]  \n",
        "\n",
        "        # Resize to 28x28 image\n",
        "        digit = cv2.resize(digit, (24,24))  ## reserving 2 pixels on each side for padding         \n",
        "        ## TODO - Before padding, ensure that there are no straight lines in the image.\n",
        "        ## TODO - To keep some gap on all 4 sides, we can pad the image by 2 pixel width on all sides and crop localised characters from that image\n",
        "        digit = np.pad(array=digit, pad_width=2, mode='constant', constant_values=0)    \n",
        "        \n",
        "        ## Cross check the image\n",
        "        cv2_imshow(digit)\n",
        "        resized = np.array(digit)\n",
        "        resized = resized.reshape(28,28,1)\n",
        "        data_arr.append(resized)\n",
        "\n",
        "    # print (np.array(data_arr).shape)\n",
        "    return np.array(data_arr)"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3T7s5JwV_WcH",
        "colab_type": "text"
      },
      "source": [
        "# Processing Hand written text with OCR and Trained models\n",
        "Using model trained on MNIST dataset improved recognition of digits in roll_no field. However the accuracy is not very good. This can be attributed to the handwritten data obtained from students.. The model's accuracy should improve if the model is trained with these new data over time. There are scope for improvements in character segmentation algorithm used.\n",
        "\n",
        "\n",
        "Tesseract OCR did not perform well for recognising handwritten names. Tweaking config parameters don't seem to improve the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoVJXV5V_aOW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "outputId": "f8cafa98-c521-4da3-b56e-b9ad0374ef11"
      },
      "source": [
        "## Load required trained models\n",
        "MNIST_model = load_MNIST_model()\n",
        "EMNIST_model = load_EMNIST_model()\n",
        "\n",
        "## \n",
        "for filename in files:\n",
        "    if (filename.split('.')[1] in LEGAL_FILE_EXTENSION):\n",
        "        ## Load images here\n",
        "        # print('\\n' + filename)\n",
        "        img = cv2.imread(filename)\n",
        "\n",
        "        ## Crop name section for faster recognision\n",
        "        ## TODO - Identify Name and roll number regions it autmatically\n",
        "        name_img = img[name_box[1]:name_box[3], name_box[0]:name_box[2]]\n",
        "        name_img = to_binary_image(name_img)\n",
        "        # cv2_imshow(name_img)\n",
        "        name_text = pytesseract.image_to_string(name_img,\n",
        "                                                config='--psm 10 --oem 3 -c tessedit_char_whitelist=abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
        "        print('Name :', name_text)\n",
        "\n",
        "\n",
        "        ## Crop roll_number section for faster recognision\n",
        "        # roll_img = img[roll_box[1]:roll_box[3], roll_box[0]:roll_box[2]]\n",
        "        # roll_img = to_binary_image(roll_img)\n",
        "        # cv2_imshow(roll_img)        \n",
        "        # roll_text = pytesseract.image_to_string(roll_img, config='--psm 6')# --oem 3 -c tessedit_char_whitelist=0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
        "        # roll_text = clean_roll_number(roll_text)\n",
        "        # print('Roll no :', roll_text)\n",
        "\n",
        "        ##==========================================================\n",
        "        ##    Processing Roll_number section using MNIST model\n",
        "        ##==========================================================\n",
        "        roll_img = img[roll_box[1]:roll_box[3], roll_box[0]:roll_box[2]]\n",
        "        roll_img, char_boundary = segment_characters (roll_img)\n",
        "\n",
        "        # cv2_imshow(roll_img[y:y+h, x:x+w])\n",
        "        processed_digits = process_data_for_model(roll_img, char_boundary)\n",
        "        roll_text = loaded_model.predict_classes(processed_digits)  #This is a list at this time\n",
        "        roll_text = ''.join([str(elem) for elem in roll_text])\n",
        "        print ('Roll_No :',roll_text)\n",
        "        ##----------------------------------------------------------\n",
        "\n",
        "        ## Mathcing with existing records\n",
        "        found_record = find_record(name_text, roll_text)\n",
        "        print(found_record)\n"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n",
            "Loaded model from disk\n",
            "Name : PleP lL LSeele tL\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmIAAACGCAIAAADxfnEMAAAxNElEQVR4nO3dd3xc1Zk38N85905VG/VebMtyx93YxhhMczAECCHAhpAQ0thsstmWd3fzJu9ms9kkm91P3vBuSMIGsgkEQlmqgQC2Adu4d0u2ZVnVkmX1rpFm5t7zvH/cGfVxwdLMGD/fTz5Bkmfmnrn3nPucfgURgTHGGGMTkdFOAGOMMRa7OEwyxhhjYXGYZIwxxsLiMMkYY4yFxWGSMcYYC4vDJGOMMRYWh0nGGGMsLA6TjDHGWFgcJhljjLGwOEwyxhhjYXGYZIwxxsLiMMkYY4yFxWGSMcYYC4vDJGOMMRYWh0nGGGMsLA6TjDHGWFgcJhljjLGwOEwyxhhjYXGYZIwxxsLiMMkYY4yFxWGSMcYYC4vDJGOMMRYWh0nGGGMsLA6TjDHGWFgcJhljjLGwOEwyxhhjYXGYZIwxxsLiMMkYY4yFxWGSMcYYC4vDJGOMMRYWh0nGGGMsLA6TjDHGWFgcJhljjLGwOEwyxhhjYXGYZIwxxsLiMMkYY4yFFeUwSQBF7FgUsUNF7Ygs9nE+ZLGA8+GFi3KYFICIyIGISAgRsetkHUiIyHy5j+jyzbWXL86H43E+jDzOhxclcmeKMcYYu+zw2CRjjDEWlh7dwwebsiJCXa+MMcbYRYlma5IIHb0oLW/v6T13z68CVKQSNfbQ3CnNGGNXsmiGSQVs31l532f//MDhEyqCU14vmMLlPOzMGGPs0kWz05WA9m6zuTNgQj9njIxWLOeBW8YYu9JFMxKYhMGAbpJLRXuIlDHGGJtQ1MIkAe0dOFlRBWigET2bkdxx4NxiJyWMMcaiJHrNOEJTc/f+g2WK7FLqRJHaaOBcKYICQFCE9k50dnjtdj09zR4XB23oNUQ8WskYY1eO6IRJApRAR1dvRUWt3eEWQhMCRBDBXXlU5Ju5Vozs9aK23l9V175jV2lp6anERPvttyz77H2LJSAErJ0kIpYehK85EBSBJLTxrwyexpgS5suc+zuGTG1mCKUh3FGsKdZTnRvPf5SJzlWYd4VqnMM1z+jWQYNJnzi1F5YHLvggl/w5k+2j5R8FACSB83wl61tbRT72vvvHR9RakwR0dPZ5BwKJiYmapiFyAWiClCiCQSivHHj+pc1btx8ur2gcDBBIE8K3c+fOWbP/c/HceJc9OsmbEEEISISiu/UVAPT1o7PTzM7WdA0S0LnofFTBroXQDY4AEFToliQBAUi+N7GpEoqRBBIAQYWqPsGfCf1edHejvaOjp6enuDgvO13n8j5FIhomh3osFaAIZSdqDEhl3W9GiVxTkgCTUN+MZ1/Y+eamPaXHa/0+BUibbhQVprqd9rITVb/53cZ/+6c/c9ohrM0JIxLPz30M6/5sRcfuflTV+fbsr/rVfz1dW9dEQkhgwy0rHv3pI1kpEBhqoCN0YiPTQhqV3PP+eWRrILThpCmEmLp0jm5/DB/FusQBE02tStNkQiJMAy0dOHT09NbtB+obmgM+vy4HvvnnD9x8XZ42OXkhzHcckcTQcUZeuzDvEmP+O5WNrLCNuBHpDF7UidtGk5W0C/mcaLQ4P1ruHY6RBoL1M6XQ24e6Bl9dfUtVTeOZxo6u7r6uHm9bW1t/f+/VS6d//+8fzE7jODklIhomR47qKaC07CQgozjUR8CAgW0fnvneD3957GSHH05JmsupF+Yl/c23vnr3nVm//f3x7//w8aq6jq5eJCXArge/QnRHKK2GjgkMDqCyuvNwadWPfvpYc+ugtCUmJqUkpWTX1re8t+PkM8+9942v3uCwRa3FM/IsDY37SqsLcPytfATrXVE7w0KYhIpa4yuP/PX0woKsrKx9B4/4fNTVa7R1egOGsGlanMNXVVW9elleYnx00hhDRrZ4AIRa4VbVV4ZeEnU0uooRI0nC6FESq4yYCr4AAn709KO6pqW65nRN3dmGM019/b7Obm9Ht7e5pau3z2caRFLqkmw6pSQKv98POKL2ZT7WotTpSlDA8RM1IKlUNHa6IZBAwMThst4f/+yFsoo+A/GSjORE88ZrF3znfz08rUBqAi6H6XDahHA/+dQ7D967bs5Mu9V6iG6MNIFeL/YcbNm95/AvHns8Ic69dNni7Kz0lKT4adMLFy5dcue9P2hpadm9/8Sn77yhIM8awBxZl49IO5KGtyC0Wr0NZ7F7z6Ebb1icmARJwRaxnLgpQpACwVdNlQk/2UpqbQP9w3d/caqmv6u71nO6SRBJQcmJNk9ScmqyZ/r0vFVL59y0bllC3KWm4Tztmwn+QZ7/XZFkxUjAVFBAazuaWvwDg36pISkxLi9buFyQBE1M3AUzxdXN0b0mBBMgQMNwt3kUDQ2XNDR4c/LcMvSrCVTW4U9v79345rbKmkafXwWUMg0KgikEJAwBJYXp0Gne7Glrr1304P0bcrM5Rk6V6IRJBfT04GxLJ1GKlFITEV+XImAqlFV4f/wfv9t7uDagHDYZmDsr6xtfu/um62ZmpUMKdPehpqra7zP3HTxeUX7YaVd/941bE9yRTul4jY3dP/jx4wcOV02bPvPffvLDBJdt2dLi3Oxg1OkZRHycrYm0+jNtrR3eglx31O4HIhh1TGDvwY4nf7fxdH1jXVO/TScyzIREV15uxpySaTnZ0Mb0u0evFqKA5nY89l/PHTpybMOtt9y+Yc3qFXlOJ2RocEgTkAIOHQ499qZKRVCwS8NEnxet7eaHOw/v23+8tr75bEu331ASKtkTN7M4b86sglvWrSgqiE+Ii0pkkgAUQQF1DYHHHnvydH1tcpLt17/8l0gnZDQimAIDPvy/x146cODYI4983VS+o0ePHj5Scby8pn8QfQPoHxD+gDAhAE2SSkxwpaclpqUmZmYmFk/PLy4qKCkpzE7XnTa4nEiMxyT1/7MJRCdMGgEcrxg0TJ2EDFaSIozQP4hX39i7ZevxALncDrXhpgUPPbD+hmtzNQFpjfl149iJ2v5BZUL0eXGq6mx3rxHvjv4wucMuly+evWH9DcUzi2bPShMKUgAi1JtEMAN+AP1en89vkpXcyCdagABDoaLa99728pc2bj9UWpWdU/DL3231evsE4HbaUlMS87I9t9ywcs2q2bOn6fZQZiSQGBpUnWrD8zAlCP4A3nn/1Otvbnvg/vXf+bt73C5IATEie9KYRvClNXjP/dZwrcao50Cr9tPRg5OV3ne27Nuy9dDx8hq/IUwlFQSR0ASJev+BY22aPPDW5rL7PrXuM3cu8MRDkxhdHZrSrxJsefsCKK+mf/7ho9XV5ffdc+tn7rwu0gF79IVUCjv2VrZ1UlO7+dwrB3t6/fd98Xs+nzeUoyQJoWma2+1OT3Z5kpyeJHeKJ654eu6ShSVLl8zNzw1+WrBLhiDBT4+YWtEJk34DJ0/WETkAfag3IWLX2aoIl1d2v/zGdoOcEuZ1axb+n3/8QnE+bAIgEkIoQkc3NbV7FWyAJnV7fuG0xMSY2C0oIy3hSw/dARlczWk1xa0zqAhtbcrn8wGQMsob0iqgqRV/+bffP3qsrW9QU9CqqyuHusI6IRubekqP1WzfcWTB3Oyf/egbC+cmWnNHo5FsafV37T3c+vff+dcZM6bdddvaBFdoLmsoOUPZdDhGRtzwnFsEZzxaZChl2tQXJQXUNviefPrNV9/Y23DWO2A4FLmJCAh2ohokoCQpQJi79tVW1zzdUL/24c/dVpQvItnoMQFD4YOddf/w3Z/3D/i+/52/uvvO+Y6oFmIrC50923z4ROuW7acqa9rnz595VWaa2+30JLoT4uPcbqfdrjvtelJiXLInLjU5LicnOTsDDjt0EcqQasQSEA6PUy8KWcYayaipO6tgJ0ilDMMwInljVMBAAK+9uf30mXZA5Ge5v/T5W2cUwGZVdYUgwDuI0hP19Q3dBF0IuJ3a9MIspyv6edJKgDaul1oIQYBhoOJUvT9AAFKSE+Pj7SKKa+YI/QNo7xhUZCxZXJLoQlFRVmZmhhCiva2roqqxtqGr/kxn94C262D9d37wxI++//WFs52R7jsKHc4Edhzs//LXv6/bbPffu2HBvIzx6z3Gxu8pTur4jx+avdXSgbITHTt3HaltaAr4zbTUpOJpOatWzFq4ID4CTSUCNm8r+/0zm9q6dRMuggQZujAcdrgcekCpAa9pQAd0pRCAvbkt8MQzH/gC8m/+YkN26piOgqmad01AVw/e/qD6Zz9/srW9+5t/8fk7bp/v0CPW9zturi8AKwsJfPqua7LzOjdvrUxLTfr6l29ftqDI4dTj4zSnA3Y77Pahdwbbi8NtR+uPUoxfHUtQIjLTDq48Uep0NVBb32RCA4RSNDDoNxVkxC4xoakF727e6/drUqrr18xfPC9Dl9Z0BChg0I+Dpe2/fer17j6TYJfwOxxaRrpnaqeUXIxQwRiN4DdxsLRy0G9CqJys1BSPPVoJthpnJ061DvrFvNkFT//u25nJwzVgArr7sOm9uieeemPHnkqT4g6XNm798FjJ9KXx0ZiIQIS+Qfz26Y2NLf03rV10yw3L3Y4YudTDCPD5cbis8aln3iorb+zsM1vb+/oHDFLCYdMSEmwvvZp4+62rP3fv9Zmpk7amM7Q4Z+xcG7vd7nDFiV5IyPRU2/w5JbOK8zLSPanJiYODvobGtpOV9UdLq5o7BwzDZihne3dg49v7Zs3I/tQnF6cmRSKQB4BX39z3+O83Ha+ov/uTa770hevjHNCisXXJhHp6u6qq67KysuaV5M8tcZyr45RbjdEWnTDp86OpuZ2gEyQR+f0BFRwbmvoKEYGAnXtOtXX4SEm3U628em52VnChggIMoKoB//dXr+09VGWoOEAAymXTUzzuWNvhdUzBUUBnL97dvNs7ELDpKJ6em5YyarZoxGZIWmeyutb4j58/4Q+ov/+bh7OSoI+4tEogNR5331a4YN5fPPTnPz1+srmrh97etH/99fNmFzulwFRtvjPRKSDCoIlnX9y77cPDycmpt968cmbhqClFETpvI7PXREc3CTUN/oe+9t3GVgQMO0kphBDQiNBnUE//4NmWwdLjL56qavjutz+XlzW8w+KlmLgDnHDzdQuamj712BN/stttv/jZt5Yu8DgdsOmQGkDw+9HZjXffK3vyD2/sP9qihAtkO93Y+/QLW4pnFqxdkaoJdZ7Vnxdr9EUygbYu/Oq3rx4/2TRndvHffevBlATrSBIRWtA18fcaWngd8JveQZ930Geaykr5xSVo3JIqDqNTJzphsqtroKWl1cpJDl0XItKjUbv3HvEOkhKYPn3agrlzrMniCmhoxP+8uu03T715+uyAodxEGgBNYsaM3Ly8pJiohY4wprSbArv21VfWtimFnKyU+XOKHHp0So8CTMILr7x7qqo+LyfjphsKHQguHrDSowEQcOqYPQOfu3/DD3702wGf7UhZVV1D66zi/Ag32hXQ2oZn/7ixtbV30VWz7rh9pRaJBISvB4Q608b+WUDX9fz8PFc8eVKy4uIcOVkZdrutt9db39Bae7q5qbXf65dvbTp01fx5n79vceLkzXEeUz6FQGoqXE6NTG9maubiuZ4Mz6hjOV1wO/GZO+dnZqX9/fd+U93QFzD1gLIdOla/5YMjKxbfEGefwsKkFDp78asntlfWtpMyv/6VB4qLXCOvaRTH7K3BkSCSzS1dB0tPLVyw2KHxpk6xK3JhcvieTjCJ/AGTIASU3aHHuVxW3rF64DGlNykBRTCUVJBERlZWdnqms68fHV0oPdH63IubP9xd1twRgIiTQieQAkmJ3Oy05MSYq7CNLO0EdHdj41s7untNQBQVZi1eNHtMwYtY8gk4VY0Pdxzt7+/fsP764bGocUN7Eli9Yn56qqv2rL+rd6C6psFcmy8kxBStEZq4aYTSk61Nrf0mkJKamJoycqWHwvAk4sk1fnh5VJJUqFJhNX+sM5KXKX/8T1/t6h6cNbs4JRk2Pfji5ha8t638v5/ZsutAeWuH/l+/37hkYcHKJamTOw43VIRJoasX+/aX9vV03rjuDveIMfuh8qsJJLmxfl3WqYduffRXr5xpMRXZvH7b9j3H769bNbvYNclTxkd0mSiBVzfu+49Hn1Zku+u2a25YO2NEF3psdLoK2B0yMcHV1UePPf7arJI5S+Y7k+LPN256nptjDHyvj6nIhclgAQOUgGGoQMAEQER2uyMhzqXpEbqJW50eds2QIiBBh4+Wf+d7f9C1wLHyqq5eo6XV8CsAUtdEfHxSd3cviKSGrAyPrk3xcvdLYAIBhfe3VRw4VGUqXQjvNSvnFuZHqdgQAOzYU75r/wldqk9+8vpzpEMAackoKc6paaxSQpxubA6YsEU84XV1Z3v7App0JCQk0ahVHjI0FyNyrA0UX9u4Y8/eXX/zV9/ITHMGtyUCnA4sXZhnvWxkTszPxJ/dMzshKaPy2z9tbjdOVTd9uOvwkoU3Oiel4zVkuFomsOWDit37juo2XLf2atdEw8lWinXCXbctO3Dw+AsbDyvYQI7Kmqbd+0pnTlsxRUVeETr78cyLm0w4XC79mqvn5WYOdaFH+lJOyKr6TCvIXnfd8lff3F19uuPv/vFnd9++/LOfWTctX+c2ZQyKzp3U7/f7/X4AQghdl9rw7MaR+XhK8rQQQgJ33b62MDdBCqO1o//NLaWvbzpxosrb2OwPmGZinFw0L/O+T68dHOxRJABoAlkZyXqEF1vR+dcbWC8hspYn4vfPba6p7zBBaR7trtvXRqe8EYjQ3IL9hysMZcvOSYtzjj5vo76XgoDDjuzMVAkCya7OXhVayD+liRz+31A2E3rAwImTtfsP9vkCI899BMqIGpnbFeA3sP3DIzOml7gcE89oGnGGrPYuNIF5c1KuXjYDwlSklR2vMoypCgveQRw9drq53StI5Wa5Rk6+E6HOdQIAJQWy0nDNqrlJ8TYBBWBwIHC8vME3NWkjwOvDz3+x5URlmyD1iZtWLl80Ux9Onox+kyvYbYa8PNeG9StSk22KtJPVnY8/teXX//3u6bNQZBXqiQq/OPctKCYqAR9LUQqTRsAIXlNy2OyaLqxcMSJzTOUlJ6xZlfX1r366ZFqiU/MG/F6fzydguB1qVnHKZz+z7r9//e01V8/x+fsUTEA5HSI3J12Tw8vMI7EdwnmKRHAq6ZlmY9/R9re21P/2D5t27q80lHBo6p47rp9fErnhFyIadb0Ezpzt+XDXYQXbymWLkuLPE611Cbfbaf3sCxiR32oCAh6P26YLItQ3dPz+j++8v/NMcweM0IUe2gEjMvtgEOH5lw5t33lo3bob4xNGDwpOnC+CkTI5HksWlkhSJmkNja1qahJLQHOrceDwKSLHjOl5jvNNCXbasOiq4tycFAgTgD8gKmsazzRNfuIUQRGOHOv4n9e3dnabNl1tuHn1nFnpUd+XbkJuB65dVbxm1WypKb+pt3TiuZd3PPH7PzW2wgSu6B2eYk8EOl3HrosiIBAIDP2qWTN4BAAIMdRJNIXPspCAQ+LeuxbkZSRu3XWkrq7ZVCIp0VVUlLXumqUlJR6XEzt3dAsKCCiBwLSi3OnTcmza8CSUWMjDCmhpx/d/8lTZyZaWjkBH92BfP3SbuHbVgi9/8S49gjUgIcTQ9s0kYBKOHqusqj1LkIsXz0qMH07JuBmGwXG3ofxg1ye1lzBsikf8TFIAC+ZOS06ytXT6O3uNP768e9+hUzesXfTJ9VevWJLsskGG0jyJUz9Gn4pRpaOnD6UnquYsWOzxxF3ALT74Xklw2OFJiodQAnpf7yANDW9eVMLO+Q4C/AZqT3fuP3CChH71ioXxrgneMNRlbXUwpibFZ6R7xKlWguY3zKbmruaWzplFKZMzUhgasSOB9i68vHFrY1OvEjLerc0uyY+P3l6NExuRmvxMfOHPPlFW3lxe3WWYelOn/8k/fNDRPfjtb36qMOcjzOiJdkP54ytKe7qqYMVcEHRdl5FbMglYa3OJ3DZxw9rCq1cUtraZpkJSouZJgi4hCSbgG+iTENZAalFhdlqqc+zDvqbYeacyDQ7infeOvbXpYHu3HlAOCB3CbrPJNWtW5mbbojbCQTCBD/ccIuiAMa0gy+Uc/scJwgzBMNHV4xVCEozUlCRNRnoMWALT8rXP3vuJx3+3qaFlcMBvLzvZVn/m/e0f7vvWI5/65K3z492Ts7hipAkjrrUJ3K495X945vkf/PP3UjzjTsM5s4VhwOsdsH6OGzFgOInrHxRw7GT3W+/u8pu6JtX8OcVxzvPdngV0XbhdDkAJApHo7h3o6RuclPQMHQKAUjhW3r1t57EBv5CaSPU4sjNjLEaGEII7zF27Kv9z96//4b8/PWjYTLK399LLr++Kc4pHHr59WkFk6ozs/CIQn8aOBwiCERgaEFJy1KO0xvS1TtVYgtV8lQIJLhTlazMKtbRk2OXwwXr7BxQIgjQE5s8pttuG3jkVyZkohec7VEeXsen9Pe3dhklS0zSrTzhg0J69h7t7g/MkRxgx+nUBo54XndrQHGYFGIQ9+0tBMj7OnZQYF9owaOJedBLo7EF5ea21brYwP9M2pYtYxn93ASEQZ8fXHl73tS/emppo6CJAsHX3y6Pl7f/26Kt/fLmsf2Dyt6Wb+CIQvD7s3nMk2ROfnZ40wdvCZwslEDDQ0dkLkpKUJylehpqiFxUjz/1SIuw7VPvan3YFTCmhCguynGMHT9X4ay2E0DRtaM2iaZBhKBAmp3QLBQCEzm68vXnv8Yomgu52yuuvXeZJCK2uiUJX/rkMdZ67HLjnjuVL5+dqwi8IphIdvfTaW/tffWNfd+9wDpmCIssuQnTa6aZpytBl13U9WsuYrJwqiTTr8Tqhe4QCvF4vAEFKCl9Bfrp1x4mpwpYYr5fMyEvz2HLS9atmZy1bNN2hm0ZAbf9wz7bth6KVUCK0d+F0fSuArIwUt8MuKeydN9h42neypqFNEyLZ4ywszB6/D18ECIGkOHzloWv/4a8fnFGQ4LIrIjLIVVHT+asnX9m5t9agSNynTIHuPrz06rvXr127bFnhxZUKQq8XJyrqlJAQqrAoO9gun1SGQnll45mzPQQZF+dOSnBro7eGn5BSGPQFQJIEhCCX2xbnnMznoBJgCrR3+kvL6/2GXQjhdsjlS2fZrdnpNLaiEDsFWSMU5uD+e24szE6WQhGkSfqZFt+7Hxw4dKTOevwki7rodLpaUyKE0ECmlHJEp2sU7pGjVh+G9rbuHxgAAKE0GZg+LcdhG/HKiG1mM8bo48bH44ufvTE9WcTFJc1dsKyt3f+tb/9rTcNAwNA3v7f3/nsWCzGyq3D0ZMQpIuD34+jRLoIdQqWnJce5HSNWVoxiTfvp6MIzL7w94LMBxsIFcwvzM6Z2wsX4jw6dVSmQHI8H712el5X0wms73vuwoquPDLKfru/44MOjSxYWpXqsJ3eG+ZyPZMyTq/u9eOOdk21dZlZGSlryxR2FgMZm79795SBdwD97VpFtCnZJCJiorWsy4QCQkZnidOlAsAYZ+iKjLzQBgLff197eZf2TbtOyM5IyMjyTt9uwBGACR05U7T94jGAX5J9WmH/j9UscoXWllqGjRfeRAKMIaMD6G5bt3H+64Y3dyg+C7jdRWdt8pLTqumsKrSfSjFj0CR6DjLzohEmbpgshQCYAh8Oh63qMXHkhhAkQob9vACQhVGKiY0aRTbeNft3IJ45HiQTysrVHHr7ZGg6sqnXOLs6qa6g0ldx7oMwg6Ih0LCeC30BZeSXBRkSZGSku99guuZG7TAz48cIru/ceLDcpLj1Zv+m6pXk5roim2CKC/6cJpCZiw/qSGSUlmv2NV97aGTBE/yBOnarv7DJSPZNfWIKLiUPnpKMLv3z8aZ+h6TZoCO55fSEji9a05207jnb2+CXpOVmeq+aVaKFa0iSOTQb8ONPYDugC8CTFOxz2c/frkoDfwPGTpxsbOyAkCA6bKJmRU5Q/mXvmWkMMe/cf6+r1A3YJWr16ZZIHdWdVZ1ff4KDP4bCnpiSmpwm7NvZhXtFlTXHyJGFWcaHLfsDnVwAUyf4B42xLu8KY571EYRUvQ3TCpIDDaQsVK+Ww61F4LPMoE9TR+gcGlQBAWRnJSYmhJ9dZaRZRmq4txv429AwBEHKykJuTImCYZG9q7mpvR076iFdPSQt43HkTMBTONLYoaBIU53LouqAxOwGFTp0JHDjS/czzW4icEubCuQU3XLvAHflnsISON3R5bTY4XXA67VJKgJSA3zSCG2+OaQBdwlkdc06stnVPn6+ltSc5JW16URGGHpR0ATFSEdo6sWXrQaUcQvhWLFuYm5U81C6frBhJQFOzv72jW0AjBGza+UuuIjR3Ysv2I22dA0RuQMU79YXzZ5x/4s9FMgllZbUKOgCn056fP/OxJ49t2rSprbPfMExd1/KyU9esnH/T9Uvmz3K77FNfgi84b5BCwIA/YCgFIgEhAaWFfWeMNCiuLFEIk5Jgtx4VAwKU3a5r0X/U8WhWaxIQUBnpKTGwJnliYsRPLicK8rPi4uJ6+v2Gkq0dyEmLQs8wEfw+AwAg7XZ7mH2zoQi1DfjjS1srqtqEEBkpjltvWT6jyC6jtJWYFaUUob0TZcebXty4/f3txw1DAUKXKjnJ7XbpUz3/lgjvvLPd5zezcpJzcjPEBfdZKKClA//+6EvHymsBpHlsn7h5RWbmyE+ehNYkAaRwpuHs4KCfSEJIwzAMpUhhwlhpndK+QTz74q7NW48ElEZkasIomTnt+rXLJnduOwH7D3lPVTeDNIIsKCj8ryefbWvr6O7pC5iSIIWgqtruQ6XVm9/ffdvNi7/yxRvjXJM/e3ms851y6xR5/di05djm93cP+Awh7IDSJCUkugvzsuUFfAiLgOh0utrtupBEREKSw2HTtOjOfB43bCbQ19cPSEkqKyMltGgu4ukKb/SNLxhbEhISHA6H8AYA+HxG8OJO3UgqjXuWHqAJeJLiACLIzu5+n39UC8xKi0FobMKjv3rluVe2eweR4MZdt638/P2rRm7VHZFnOAynylTo7seZZrz48vsb39lTUdUaUA5TCQEzLdm9cum8jFQ5vt15KWd1zGWxHk3zzuYdAQN2uy0hzoUwfRbDG6uG/jLgw+tvn3ju5Z1dPWST6uZ1S65fPcs+oj0yiWdSSimEIAFA9vYNeAcNkvbx9QcCAgaa27B97+mnn3+/sSVAcGjStGveq5fMzMsR2qQuWFKEzVv2dvUpgg2QJ07WQ1gdscH7G5EcDGCw02zfV3/iZH1qRuGdnyj2nG/ji0syLreMueJWjOzsxqFjvc+/suv4yWZD2UASwpAikJ+bUlKcM/a6RWtWxBUv0mFSACTgcNiG9hRwuuxapB/Fe04Evw+9/QOSAKHSUj0RTtyFRIiRN0oFaT026EhpdU9vvwTZdZWVEalNckfTbVgwd4YGvwHH0bJTJ6vbsjLTnHqwZ5gETIWaejz17ObnX97aNyCk8K9YMvvLX7g90Q0RivdTGiNHzZoh+E20daK6rn3L1gM7dp/YdaDSb8SZppMEJHxxLnPN1QuvX7t4aM+4qZp4SFCEQ0dPGuTRNM3qbpnwFISGM2GdL+8gXnj50L/9/MXOblNCzJiW9rWH787Pmfw2uQAgkZ6R6nLbRHuAhKitbzl4tHrm9PlxzhERnUCAL4DjFf0vvPTeW5sOnqztVnABShcDKxYV3faJq22Tlzetqxkw8OGeo76AjaABCsIU8NskZWYlJ8a7lFIdnf3tHX0G2U24O3r9T/z3q7Omf2HFknRtqnsIJvqLNX/Vb6KhUW364OCLr+05cLjO69dJaRBKCsOl+1csLlm8aLqI/hQIBkSrNelyOEgIEtBIuex2PTqpCKvXC8NQADSBwoKcCHd9CEFD648nEool1swFwkAA+4/0vvrG7j9tOuILwCYDSxbNzMmchBbP+RI6wd+cdqxZWZSVHtfQgur6jp8/9mpn14b5c7JTkgQILR2B8orGjX/asfHtPYap2YQ5pyTzX777lTnFmhTA0PNhpvLeIISwziEBXf147U/lH2wvLTtZd/LUmQG/IMSBNAilSzM5Abffsvibj9xTMsM1dMManpYa5gxcaDJG/0rCaoEpImGaKtRxPdLokWABBXT14s1N1b/+3eam1gAgc7Psn79/3dxZCToF6yWTe/UFkJfrzs9Orz1dR3D2es3nX9rh8WQuWZDuckIKBAwM+nCionnfoVPvbz1QXtnY6yUilxDKrhnzZ+U8/MAtc4oTRPg21gUJvZkQLC1d3SgvP+03rMe1BXTRU5CTcM3yOTfeuCo1Od40Vf2Z1k3vHfhgZ2WPVzPIfuRYbdnx2uWL0ylMo3aymm1i9M9WI7urD6eqevYfrd6zr3zfoYr6s30BQyNoEApQNhlYvmT62mvmJieNuwVwyIyS6AQot1tz2DRBCkK53e6YCpMK8A7AMAlQifGuzPTk8blzipo7wSfFQyJU5SQCJAQFIyIRiGTAhDLhD6Dh7MDm93cfP1FfdqKusqajf1A5bWL+nNx//NuHIrlZ3cjEaxLZmbj/0zf/5qktPV7auuNIVe3p2cXZaamJEmhs7jhe3tDW6VVk16S5YtG0v/rmvYvmOcd3wU3FGR6z+mLQh81bjvzo35+ubzIDykZwEiBgOmym20EL5k+79eZld6xfUjzNpgHiwmacfsTEhAYhravf3eNtONuxaEGiKYIVIiGgKLhlnjWG6h1ASxv94YV3n3jq3bauAEjGu9WD99/61YfWJDpD3/BSTTC1ze3A3JLcQ6U1vT7DVNqHe05WVT961fz8vOwUKWVPT3/D2bZT1Wdb230GOQkaQUqYDj0wc3ryFx648fZPXJUcP8EZuEStrX2dXX1Wm3XGjNxHvvCl+++ZlZoQfKwpAEWFt9227Ps/ee/3z74jpN0k/fSZJgVoke3eDxg4VtH10uvb3t9aVnm6o2dA+g1NmXZACkECAYduzinO/PSd1y5blMMxMXZMYYAKVyMTBJuOhHi3aO2RoIR4t30ylxpPgv5+RQQBlZ7mSUlOnOArTE25GprxSAQjtKG1VXXu6obXi54+tLX2VNedOX6ipuxEdUNje3tn34A3oEypAA2+eTMzf/qDR5Zf5Qkz9jOF666scyIBXeDhBzf09AWe/Z8t/YP2ujN99WcqRhxaANJl8669Zv5ffu3ua1dmD63uG3nDmoozPGYPVZ8fx8prGlv6/SrJqutL4UtwmksWFH7iphW3rb+6IM/ucmDi+aKXnLqRnyaEEAQBuJx234DW0t53uOz06tVFnoRgWolAAgpQJjq60dyGnXvL/7R577adh/sHhCCRlSbvueu6Lz14c/xkLqiZIJ/YdNy0buGZ5rZ3t50c9DtMOBvbjLPbTmkgQBKRSSDSCPGAJJAUhts2sHJ58YP3rrt53YKkhJHzzgQu4UTS8D7CUCaUENbzXlx2Wrt6Zmo8dASfn6UAQRjoR3V1tRDS2lvAZrOFUjGF956R90ACahu8L7y2+w/Pb2/vNP3KpkgSdAgpoKQw4p1q8dzsz9y15s5blyQnTlhKed1kdERrewEkJMRDdEIF4hOcwXmvMcMIBJ96kZeblZWRLCM7QuDz4Qc/emLT1iO63WMSTNMMBALKtFYlKqWkz28O+MWgzzQNAUCTItnjyM5MunbVnAfuu/Gq2fGO6FU7BCCBgjz9r7/+6dycjFfe3HG2qc/r81nbE9rsWpzLXlSQ/sn1q269Zfm0XOEMbU03PDMlUrV7mx2zZk2Ld5pmX5fUkJebuWDB3BvXLlu9bFZetpYYDz2SC+wENML11y578/1T/X2+p557u39w4NpV87IzEtxOJ4A+r7ejs7+hsf3o0code0orq1sGDZsS0qapGYUpD3325i8+sDopHlOwo8AoUmDNquL4xMTevuf2HKzx+TRT6CB7gEiQDigSEDAF/JpQNhGYXpSx/sZ1n77jmqtmJUzuLuRWnRIABHSbtOvCMEhA9HR2mf4A4ECoS8YU6OzCpi2Hjp+oAiBI2TSVnZEa6WhDqK1tOHK0orV9IKBcCpoQJIRPkuHQKS/bs3TRjM/csXrtNdM9ied7PjOLrCiESSLoOnKy0w+V1jjsMjEuzq5P/jjKRaQHwMgZaAod3T2GoTShsjI9aamuSKZLAY0t9Npbe+rOkjHBlrbKGsAAYNNlWpozLzslI9W9ctncW9evmjs7XsO5Hyww+XcGCjZ6hz9ZADaJojx865FrH7j32v0HKk6cquns6iNT5WSlzZ07fcnCwqR42PThPjEgOMgkprh2j1AYFoDLjjs3LCwq+OHphuaczIx58zPj3BACGgW3pb6wtRi4xLMaTA9BBx568PaK2qdOVHacbhr4z8fffuXN/blZKXFxTiLq7x9sam4/29QRCJAiKYRTk6Ynzlx/05L7777hmhUFCXFTcm8dUzoEkJqElcsyvv2Xn/rD8+9sfr+0s3cwQLoQUsAElAZTiMEEt1w4r2jJouJ1a5ctnJefmTrRov6PPAAohv9rtSkzs9yFeVkVdV7T1BqbezZvK3O7l6anIGBgwIe2TmPLB4deen1bV68i6FIEcrKS584qEgKCQJigWjZZp1GM/iU3J21mcc6BI5WdPX4BU4qAJ8E+vSBl0fzpq1fOXb5kdmGu02UPn4Dg3HJuU0ZaFMKkkNAkUpKcGgY0DXY7xVa9SUCYA5L6bbInJ8OdnBjR+E0ET5KYN3d2Z39N/6BUSgGQUrrdbodNuty21BSPJ8mdkuLJzkgqys9YfNXMgjx3igd2HZEZ4bsQAtAE3DbkZyL31pLbN5RY90QJCBG6m1NovmZkEzh0QqSAy47lizOWLcrQADF0H49GeqQAAddcPe2fv/vID378m9ITZwxy1pxura1vkVYwpqE6EwkEkpPsVy+96rP33XL14vy87OAuepG51AKIs+O61fkL539598HGg4cqak43tXf2mCa57I6U1MSioqx5JYVXzc9N9SDOheDSlBFBcRKzpdWmTE7E+huXNjzzfm8/Kdh+87tXd+09lJuR5PMNdPcONDb3nKxs9vqkIk0gEO/wPXDfXbNK0oNT8yK1aaoAZhanfOFzt9nt9l37yz1JadOKshZfNXPlspnZ6XA7oOvDFZ1olVw2IRGpJ82Ouuq9Xvz6qR3/+pNfpqbG/+zH37n95kJNRGlh+WjW0GBLG37+6JNnzrY9/MU/W7e6YOwQylSuXrKW3h86eqas/MzgoDLN4DiK02l32HWny5aW7PEkx6Uku5M90GUwysgpTNGlopE/jZwsGhtiY4Pe0B8J/QHsPdDw9LPvbP5gX3vXAMFGJAAlBAmYLjvmzJm2dtWSdWuXFxak5ebYnLbodNBZJSUQgC8A04QiEEFalWANDhusJ71EJm0moazC/Ppf/2Tf0TYDTgFTwJDWWKUASCME1yTZZf8Nq4see/Rv8zMwpcvQRl3fEVNzB/xo7zJaW3udTmdCvNPtEvFx0LWYLsIsQmFyDINwth3/+//8vKgg7ytfvCcvAyIGwuTQpADrse/WeQk2tyMVJgGQCk73H3Nhhto61kTYEVufcCfM5SdcJlIEAgyguxel5d6602e7u3ptNluSJ27G9MJZxcLa5k0LzU+J1o01bHMnGqMnBBgKTz69+xdPvl1V1+NXEjT0PDarj92w65SW4ly7as6XHrx5zYqMyd3fYMIkYaLlQ0OFesz9jgNkLItOmLSqov4AhAiNUZ3zxYhwNrLC5PjbUMSSQhjTEz1y3zIuUR9vQyvQDRMGgRSEgJDQBaQGAQg1oouYAQCI0NKJl1/f86snX6qsbTPJRcGKpBIwHdJYMC//U3dcd9eGNYW5uh5+y9RIJDWU4Ag/6Z19ZNEJkxclWmFygkNOdTsy7IAEtxevHJfNtbZuHTEyhGbdxgJA3RnsPVhTVXu2va0bUiTGx+XmpJUU58+dFZ+SCNuIXpkopZOG5uiKy+daX+GiGSbH7E4pojxwzVmWxSLeyPPCEQVHK0Y9bkrAejb4OSeBMxZWFMLk+EpobNwIYidMxk5KWPTFRun4WCDu62QfRRTuxUObng//JcxdgKAoUo8hJRJRj0wXX2VR/JjWjzciClc62EUTiGqM5NJ6ueImS9D4zt7It7NjZJiHxQ7OEoxFXYxO4RmfpivtbnERXW3cK3fZm8xuds4OFyD6y8/YZYTzCmOMMRZWjLYmYwHXylks4YldjEUHlzrGGGMsLG5NjsF1dhYtnPcYi0VcJhljjLGwuDXJGGOMhcWtScYYYywsDpNXKO5FYLGA8yGLfRwmp0qMl3/e3uUKwfmQxYIYz4fnxmFy8g3t7R7LOSOW08YmBedDFgsui3x4bldKmIzYFRr5LLBYrilf1rn28sX5cAzOh1HB+fCiXClh0hKBzHEZZYXLKKkfM5wPR7qMkvoxw/nwAnFV7goV1SdgMxbE+ZDFPg6TjDHGWFhXVqcrY4wxdlE4TDLGGIu+mO3a5DDJGGMs+mJ2lJrDJGOMMRYWh0nGGGPRFLPdrRYOk4wxxqLGWhQUy5GSw2SkxXJuuFzwObx0fA4vHZ/DSWHFyJgdmASHyciLndwwvpBfyF8ib3waYuccXr5i5xxyPmQxfiZjuqnL2HgxXvFkVwjOh1cODpOMMcZYWNzpyhhjjIXFYZIxxhgLi8MkY4wxFhaHScYYYywsDpOMMcZYWBwmGWOMsbA4TDLGGGNhcZhkjDHGwuIwyRhjjIXFYZIxxhgLi8MkY4wxFhaHScYYYywsDpOMMcZYWBwmGWOMsbA4TDLGGGNhcZhkjDHGwuIwyRhjjIXFYZIxxhgLi8MkY4wxFhaHScYYYywsDpOMMcZYWP8fGezexqaxGykAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=610x134 at 0x7F3E6189BB70>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "32132\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAYklEQVR4nGNgoA5gjvJE5jKhSMo4s+CW5FNixinJJMfDgFOS1UUWtyQjNwtuSXSAIimvgkdSQxePJCMjHkm8do5KMjAwMDC8eY9H8vRFnJIvn33/gcxHifrLm379x+cG4gEA/NANXCz9jvwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F3E618DADD8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "57885\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABMUlEQVR4nGNgIBcwIlhsMppKzlwbV7/6DxNigctJOzma8DAwxP9d/gFDUjQsVfH/mdV/orxPXviHZrp4/rVf95YE8jscftGtiGa1QOa179eKNbg5S17/u+yDaiyTkrfKnZkrXv3n5ub8/+MnqiSbpeHPnatfMjDJKrH8PHEVVZJHUfDmwdeM/MpRTmzf3n5EldQwZr135bdYsLeJGCMD3JtQSTEZFkk3Q80IdSYGhr9/0ALhzglRvco/3LxvGQRZ7l39jSp5YxaHpwzDu9O7hGJE711Bk/x1auIzSYabu667BTH8/YNmJ8PP03fZGb6+Fzfl//kRQ5Lh53MGBgYGCTP+uwffwSWZUEKRiZXx/c1vOCTRAEmS/3//wy358dQLPJKnn5NpLD4H/X3zAZ9qogEAiKNwROnDxHEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F3E618DADD8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "47431\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABRElEQVR4nGNgIBcwogswcaoqMX+/+vAfpiS3oIS1jTQL67ZpTxkYGFiQpdhlzdTYtNi2CUU5rMOQ5NBSf3Fx/a/HzoGsTAzokl+PX/z48T+CjyL55zXEYgl2qOOw+EDeRfD3PxySLFLyP069wCEpaC/78fRz7JJs+g589x/9w3AQAwMjP79qsu7Hg9cwXcvAwObqp6DLvGvnRyzuZFCe/+P//2elggzYdMpJPGPiFzQQ//Afi+Ttydzsfn5mFvd/YpF88oSBW9lLUp7lJ3av/Pv6HRaRmJJ/Hzxn+I/VQQyMbIqWYn///MeUZBHk5jFxdOI/efE3QpJbnpuBgYGBgd9enVND9v+ZKYeQJOVLtRgYGBgY2GX5fv97fHLtrq9IdrIKikF4ny6d/fLgxOOvMAcwMDAwCBkKQbnPb3z/8wspoZALAJP/YUM+qqAgAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F3E618DAA20>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "51000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABw0lEQVR4nKXSy08aURQH4N/ceYDIBLASEXk1PtMCkdbWaIirtquyIK38jd2YxoVxaXyQaKNGEQ3SBhQQCXZAGnkMjxkXcGfotj2rm3z3nHvOyQX+NRjtYF6KWuMZoFPKN9S/ccT35tMH810NaF7Gz2+b6jBOfFmfEQkAME/ZnY1kGwC4vhHRO3ad6wLgPP6QIZf/rWpIbK8d59vJDgD+VXTN9f6s1tbQ4I/MbMULCgBS6plW/dPJNgDSx7mQUP6jAIAinV7IL5wiQ5FYprh0utV/XmnUe7bgS46iMBvkf93I+vSWBRehyLu9zfu6qiNr4GlZYnORy0RdN3qNAODml8VCoTW000axotBMu3tU1YsyDB4OU11tlOEQnB7jU16imZzADpUUF0NsptgZvMk45q26mRZWPJUfqTZF39txDUcC0TB/dVJWtG55otvXz97KcUqmo6i5hMSaRRaAMRCLeKtHR+UeAIAD1LvkR08gbGwAk5GIu7q3cdYERbRKJV9QCLeA8cWpx91vcUkZdAeAnV6PzZKOCrBy8fj7QXVg4AD0bjaVtQmHXS5Us3unPx+1ZfU/mDDpdr4L1PbTUqZG0/4rngEToKGuiTxLxQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F3E6171F2B0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "38251\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABUklEQVR4nGNgIBcwonKZWBkZGATUBb/fffibgYEFRY5V3ViQgUHcQuzxohfokhw6Meb/fjGw8v5+8uQ3A5qkZITb2X3vGRgYfj+++wtVkpHPWOPo/HM/sDmIScjB8+2qK0hyDExwFrt5pNjBi8hyCElGCVvF8xd+M2CVZNa1Zrv3CtXXcAcxCokzoAMmJDarIDcOnQwM/0Vc35x+/BWr5N+/3HaKp1ce+fQfU/LfvTPcoupSApwH3v3DsJyR37Zsx8d/H7ZHiTFiSDIwsgh5r//078t2N7hpCDv//3l3kE9Fh1tJihFTkoGJW0qOm+Hvd0QIIgKBT87Y0kqa4cvF23/RJXkVzR0M5TiZ/jw8fOcfqiSjkHO4vjTHvz8vL+87hAgGiCSPTbIt59/Pzy6eOHH33R8MO78/ZPh6+fjpB1+QI40RaqyGKMOPh4++YwYOeQAARmFwvkIO5NEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F3E618DADD8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "50237\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABqElEQVR4nJ3QXWvTABTG8X/SzmRpqa4a6rqSFitbJFUcFBzKBK/Um6oIguAX8cP4DXol7HJMZLPgGOJLZKyCIy0Z1dalbo1rXRMvkkJSvNq5PD/O4eGBs44wvRAT+GP/f5iUZ4vl2Z7ZGw29aZwpryzoFaXzvrW30/UgGUW19jyXSiVK+vEH3vyZQkU97QBkLt8yzZY/eZua6x9BZkkFYPFp5eur193wJLXyqBB9/9Jy126DCCDml4XDCDpWX8pfCFExis4ggt7+rosQoDivD9rRYF6ndQIByjeW2nasJW1RwQ/wXEnz/sawUBZsB0QQckXZj7WoXsl0N5sggrx8/Ufbi1jSWJ3rW8Fl4Y76ZS+KuVV9vLvvgQjazfTv48hfybibPWg0A5TSsYKlSk0/3Nhy/KnigWTOqD3Ortc/jwhR1uaPxoCQSJSePNCzBw3TJcDTYfrez7oNnL+WN+5f/bXeWOsRYnt7ofxMtYCLVS0tWRt1szcEQACl+uLhpcEJMJMZ2x8b7z65kwDg7jCqSgDY399uN53RJJ0AoJQKYerut74Xr/Js8w8+e48Yk3f+qwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F3E618DAA20>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "73950\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABwklEQVR4nJ2QS08aUQCFj/OQR1uR51jwgSZWrCRag4mpQXRnoomJC5v+gv6L/piulI3toktibNKqsak2bVOigDoZJDhEESgM8+B2wcwwRjd6Vjf3u/fknAM8Vl3GgaLsQyEGQD2X125D2t7/MvgqagNwndo6l9qYaUNvPBHj3D00ADnQt7vHqxb3iQ8lmRBJECRC5NLuO5/1J+vxXBeb4je8Dvq9XufC4Y3Sgf+E8o9kvppBKji/MmCLLVcyqglr/BW/nQFQ6D5R1/vCq6dCDaDaPfwRKV0FAMh/Pv1SmUDIAQO6ZqYvD67aJs30lyKckTBlwN6pwXpZ0ZOLBxd4Gh2hdchyIa3YMGopVRm007TtiY3ndwr3TAqAHZntL2crd4enANgnJx0gnTtihbTbTVves8+6odUbZhWr2NFEELXfOe0+6Fla41BPn7XM+cyIDDezOMyol/kGOtA9+rcKwBeNz4+zWu7jnqRDIitk6K1fBBCOR/ysmttIZlUdysc/e11zY00AT3w2KNnN5ImxJajAm88VoksR999HWD0AgFYpRaSp5w4AlYJ49PX7mWoN2eV6MZvgAGR2eF5otu4u+UD9B9OLrHMTdgowAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F3E6171F2B0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "55335\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABSklEQVR4nGNgIBcwonLZzGI4Fx/8DeWxoMixm0Ux773xB6sx7DYr9vqwM2KVY7Ndca5IDIf9eouvVcog62NCMLltLO5ue/ofqySXWwTD9jvIcgjAqLH083oDVDG4TjYLM6Yr93BIytjL/vnxB4ekpgnbvau/sUtyKwoz3ruCJgkLPnkXoQ8PFfWYGT5cevUfTZJFSp79s1yeBgvDm+WrnqL5R7T57f+/33/9////701ECEJ1cqsL/f/96949BmUNlagbO/6h2snA8HH3xatXGGwK9JVdLz7FkNy07vdvBgZffQ5ZXgZ0SS4lgY9sEraSDO8PPkaV/PPxp2CE6FsGeQvZ/2/vf0V1LVfg4R9/v3/58uPf/xfdigxogDvkwOe///9+f32oURMepPCI57d1sRZ5c+Lhmavv/2BIMrCKagt8uPr+N/a0RyIAACsPeUGmhfaKAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F3E618DADD8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "55973\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABaUlEQVR4nKWQS0sCURiG3xlnnNRsUkwQu0heFlGZuEkhDNdGrfsd/ZW2EbQO20hgteoqQWItNCujG0qal9TUHM+0GBEcp019mwPnOe/5vucD/lqU/IJhaXDOSaB4BKbvpZ5X2T3D0LhdlHDag2Zjjh7n6IVFndWlgZAviOUYJEhzwZUbdoknoxYGjXi2dp4QWy/dnobldc8HZWDeLitA9eqxU65K/QFAMNlPom0gn6wBpC30hgOAaqZyvdsaVKGlQ6UfUvDsQm0gZOd+WcVcuJjeCgyEJc/7w3mHWac6aypGZzcLpBIOahQh4z/oiPVtZ/+quwMJt9EctD6fVgmiFMsBtuAEpQRJmwCs100rQZbnAPE9LypAZmbNCpBUisg9WdbkDa0aQV5TdcjgiN8z5bPpITzsRGpyR3+k1OiIopDcsNCQJ8emeUpoluL7e1kMwMwxpU4nni4yn/I/KUDtcrDPd1/fRM7+UT/B+HjZ/Z9K4AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F3E618DAA20>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Roll_No : 143050065\n",
            "[['Prashant Saroj ', '170050065'], ['Pankaj Kumar', '193050065']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E9o88avVEgY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' This code finds the regions with all the boxes. i.e. this code will find the Roll_no region and Name region separately'''\n",
        "\n",
        "\"\"\"\n",
        "img = cv2.imread(files[0],0)\n",
        "h, w = img.shape[:2]\n",
        "kernel = np.ones((15,15),np.uint8)\n",
        "\n",
        "e = cv2.erode(img,kernel,iterations = 2)  \n",
        "d = cv2.dilate(e,kernel,iterations = 1)\n",
        "ret, th = cv2.threshold(d, 150, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "mask = np.zeros((h+2, w+2), np.uint8)\n",
        "cv2.floodFill(th, mask, (100,100), 255); # position = (200,200)\n",
        "out = cv2.bitwise_not(th)\n",
        "out= cv2.dilate(out,kernel,iterations = 3)\n",
        "cnt, h = cv2.findContours(out,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "for i in range(len(cnt)):\n",
        "            area = cv2.contourArea(cnt[i])\n",
        "            if(area>10000):\n",
        "                  print(\"here\")\n",
        "                  mask = np.zeros_like(img)\n",
        "                  cv2.drawContours(mask, cnt, i, 255, -1)\n",
        "                  x,y,w,h = cv2.boundingRect(cnt[i])\n",
        "                  crop= img[ y:h+y,x:w+x]\n",
        "                  cv2_imshow(crop )\n",
        "\n",
        "# cv2.destroyAllWindows()\n",
        "\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxZjfgYedYk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np  \n",
        "x = [[1, 3, 2, 5, 4], [1, 3, 2, 5, 4],[1, 3, 2, 5, 4],[1, 3, 2, 5, 4]]\n",
        "y = np.pad(array=x, pad_width=3, mode='constant', constant_values=0)  \n",
        "print (y)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}